{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project is an application of what I have learned in a school course, we will use the dataset in the _data_ directory. It is broken down into training (train), validation (dev) and test (test) data. <br>\n",
    "\n",
    "We only have training and validation data. The test data does not contain the answer paragraph and should be completed with the results from our NLP model.\n",
    "\n",
    "The dataset includes a corpus (_corpus.csv_) which contains all the passages and their identifiers (ID) and a dataset which associates a question, a passage, and an answer which is directly extracted from the passage. Note that some passages contain HTML tags and you will need to pre-process these passages to remove them. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is composed of three subsets:\n",
    "- _Train_: training set of the form <QuestionID, QuestionText, PassageID, Response>. The goal is therefore to train our model to find the passage that contains the answer to the question.\n",
    "- _Validation_: In the same form as the Train, it will allow us to validate the training phase and test the performance of our model.\n",
    "- _Test_: It is of the form <QuestionID, Question>. Our model must find in the corpus __corpus.csv__ the most relevant passage or passages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"./data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:997)>\n",
      "[nltk_data] Error loading wordnet: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:997)>\n",
      "[nltk_data] Error loading stopwords: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:997)>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importation des bibliotheques \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.read_csv(PATH + \"corpus.csv\")\n",
    "train = pd.read_csv(PATH + \"train_ids.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>paragraph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The Normans (Norman: Nourmands; French: Norman...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The Norman dynasty had a major political, cult...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>The English name \"Normans\" comes from the Fren...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>In the course of the 10th century, the initial...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Before Rollo's arrival, its populations did no...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                          paragraph\n",
       "0   0  The Normans (Norman: Nourmands; French: Norman...\n",
       "1   1  The Norman dynasty had a major political, cult...\n",
       "2   2  The English name \"Normans\" comes from the Fren...\n",
       "3   3  In the course of the 10th century, the initial...\n",
       "4   4  Before Rollo's arrival, its populations did no..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>paragraph_id</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Who leaders the sub-divisions of offices or di...</td>\n",
       "      <td>7544.0</td>\n",
       "      <td>deputy assistant directors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Besides using 3kV DC what other power type is ...</td>\n",
       "      <td>16461.0</td>\n",
       "      <td>25 kV 50 Hz AC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>How many other cities had populations larger t...</td>\n",
       "      <td>11041.0</td>\n",
       "      <td>Twenty-two</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Did von Neumann rule hidden variable theories?</td>\n",
       "      <td>14002.0</td>\n",
       "      <td>von Neumann did not claim that his proof compl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>What is the name of the book that has the laws...</td>\n",
       "      <td>6848.0</td>\n",
       "      <td>Torah</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  id                                           question  \\\n",
       "0           0   0  Who leaders the sub-divisions of offices or di...   \n",
       "1           1   1  Besides using 3kV DC what other power type is ...   \n",
       "2           2   2  How many other cities had populations larger t...   \n",
       "3           3   3     Did von Neumann rule hidden variable theories?   \n",
       "4           5   5  What is the name of the book that has the laws...   \n",
       "\n",
       "   paragraph_id                                             answer  \n",
       "0        7544.0                         deputy assistant directors  \n",
       "1       16461.0                                     25 kV 50 Hz AC  \n",
       "2       11041.0                                         Twenty-two  \n",
       "3       14002.0  von Neumann did not claim that his proof compl...  \n",
       "4        6848.0                                              Torah  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To remove tags\n",
    "def remove_tags(text): \n",
    "    result = re.sub('<.*?>','', text)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To remove punctuation\n",
    "def remove_punctuation(text): \n",
    "    result = re.sub(r'[^\\w\\s]+','', text)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To remove stop words\n",
    "def remove_stopwords(text):\n",
    "    stop_words = stopwords.words('english')\n",
    "    filtered_tokens = [word for word in text if word not in stop_words]\n",
    "    return filtered_tokens"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
